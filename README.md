
**Course Title:** Python for Public Policy

**Course Number:** IA 6650

**Instructor:** Rebecca Krisel

**Instructor’s Columbia Email Address:** rsk2160@columbia.edu

**Semester and Year:** Fall 2025

**Credits:** 1.5

**Prerequisites:** N/A

**Meeting Date/s Times**: Saturdays from September 20 to October 11, 11:30 AM – 3:30 PM (3.5 hours of instruction with a 30-minute break)

**Meeting Location:** IAB 410  
   
**Instructor’s Office Hours:** Fridays 9:15am - 11:15am, sign up [here](https://calendly.com/rsk2160/office-hour)

**Course Description:** Whether you're working with datasets, analyzing speeches, or dreaming up new ways to improve the world with an app, Python can help you do it faster, smarter, and more creatively. This course is a practical, hands-on introduction to Python programming for students entering careers in  public policy and international affairs. Designed for complete beginners — including those who *don’t think coding is for them* — this course takes a "Couch to 5K" approach: we start with the basics and build up your confidence and skill through consistent practice, guided walkthroughs, and peer collaboration. Though you will develop a critical mindset around how data, language, and algorithms shape the way we make policy decisions, this is not a theory-heavy class — it’s designed to be hands-on, applied, and confidence-building. By the end, you’ll be comfortable using Python to explore real-world policy questions, tell compelling data stories, and continue learning on your own with the help of today’s most powerful coding tools.

**Learning Objectives:** 

Over the course of four intensive sessions, you’ll learn how to:

* Write and run Python code for everyday problem-solving  
* Use GitHub to collaborate and track your work  
* Clean and analyze messy spreadsheet data with the Python pandas library  
* Create interactive visualizations with Python plotly library  
* Explore and analyze political texts using the Python NLTK library  
* Build simple games and apps with Python and generative AI tools like ChatGPT

**Grading Requirements:** 

Final grades will be based on a combination of participation, in-class presentations, homework assignments, and a short final paper. This course emphasizes active, hands-on learning and collaborative exploration, so consistent engagement is key to your success.

| Component | Weight | Description |
| :---- | ----- | ----- |
| **Participation** | 10% | Active engagement in class discussions, group work, and coding exercises. |
| **In-Class Presentations** | 35% | Working in groups of 2-3, students will have 5-7 mins to share how they applied the code for that session to a new dataset, explain their findings and describe their challenges in running the script.  |
| **Homework Assignments** | 30% | Four structured problem sets designed to reinforce core skills.  |
| **Final Paper** | 25% | A 1,000 word paper \+ code project applying at least one of the Python libraries from the course to a dataset and research question of your choice. The final project will live in GitHub, helping students build a professional data science portfolio. |

**Late work policy:** Extensions may be granted with prior notice. Unexcused late submissions will be subject to a deduction of 10% per day.

**Attendance Policy:** Your class attendance is mandatory. Failure to properly inform me of a foreseen or unforeseen conflict before class time will result in a diminished participation grade. SIPA no longer offers a Zoom option for class.

**(New) Policy on the use of Generative AI in this course:** Generative AI platforms like ChatGPT can be helpful learning tools especially for beginner level coders. For this reason, we will test out how to use these tools in the classroom. I cannot control your use of Generative AI platforms to complete the homework assignments but I would encourage you to try to solve them on your own first. Learning how to code is akin to learning a new language. It wouldn’t make sense to always rely on a computer to speak for you. We will also review the proper way to cite when you use AI tools. I will not penalize you for using these tools to help with writing your projects, as long as you are honest about it.

**Required materials for purchase:** Bringing a laptop computer to class is a requirement. There are no additional materials for purchase required for this course.

**Weekly class structure :**

* Lecture (15 min) - weekly slides available [here](https://drive.google.com/drive/folders/1KWjnql9QO0k7hqnRvC4h-nlwMSvkCioO?usp=sharing)  
* Hands-On Live Coding (75 min)  
* Student-Driven Work with Faculty Support (60 min)  
* Student Presentations (45 min)

**Session 1: Python \+ GitHub Foundations (9/20/25)**

We will learn how to use Github, which is an industry-standard tool for collaborative and individual projects. GitHub is a web-based platform for storing and sharing project files online. Having a GitHub page with evidence of your programming work can serve as a data science portfolio when applying for jobs. For this reason, your final projects will live on Github.

We will also dive into Python basics\! We will cover foundational concepts for data science in Python and become familiar with [Google Colab](https://colab.research.google.com/?utm_source=scs-index#scrollTo=qL_eyskFWx18), which will be our primary way of interacting with Python.

* Topics covered:  
  * What is Github? Why is it important for data science?  
  * How to use Github for collaboration?  
  * How to create a Github repository?  
  * What is Python? What is a Python Environment?  
  * What is Google Colab?  
  * Python syntax, identation, variables, and comments  
  * Defining variables, functions, lists, loops, comparisons, and conditionals  
  * Troubleshooting common errors  
* Curriculum for this session:  
  * Datacamp: [GitHub and Git Tutorial for Beginners](https://www.datacamp.com/tutorial/github-and-git-tutorial-for-beginners)  
  * GitHub:[The Basics of GitHub](https://github.com/intro-to-text-analysis-F23/week3-github-tutorial-478184?tab=readme-ov-file)  
  * Rebecca Krisel's [\_Intro to Python](https://github.com/rskrisel/intro_to_python_workshop/blob/main/Intro_to_Python.ipynb)  
* [In class worksheet](https://github.com/rskrisel/intro_to_python_workshop/blob/main/Session_1_Student_Worksheet.ipynb)    
* Additional readings/resources (not required, but useful\!):  
  * Tutorials:  
    * Melanie Walsh, *Introduction to Cultural Analytics*, [The Command Line](https://melaniewalsh.github.io/Intro-Cultural-Analytics/01-Command-Line/01-The-Command-Line.html)  
    * DHRI: [Introduction to Git and GitHub](https://curriculum.dhinstitutes.org/workshops/git/)  
    * Melanie Walsh, *Introduction to Cultural Analytics*, [Git and GitHub](https://melaniewalsh.github.io/Intro-Cultural-Analytics/04-Data-Collection/04-Git-GitHub.html)  
    * DHRI [Introduction to Python](https://gc-dri.github.io/Dhrift-GC/workshops/python/) (Introduction \- Lists)  
    * Melanie Walsh, *Introduction to Cultural Analytics*, [Python Basics](https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/00-Python.html#)  
    * Datacamp: [Introduction to Python](https://app.datacamp.com/learn/courses/intro-to-python-for-data-science)

**Session 2: Principles of data analysis: Data Manipulation with Pandas & Data Visualization with Plotly** **(9/27/25)**

This week, we will review the principles of data wrangling, cleaning, analysis, and visualization. Wrangling is the process of transforming data from a raw format into one that is legible. Cleaning entails making sure our data does not include inconsistencies such as duplicate entries or information stored in the wrong format. Analysis and visualizations are ways of telling a story with the data, and uncovering insights that may lead to new research questions.

We will be using the Pandas Python library to help us achieve our data processing goals. You can think of a Python library like software that works specifically for Python. Just like you might use Microsoft Excel for data exploration on your personal computer, in Python we have libraries like Pandas that we can download and then import (a fancy word for open) in our Python environment. Pandas, which stands for "Python Data Analysis Library", is specifically designed for data manipulation and analysis.

* Topics covered:  
  * Working with tabular data (a.k.a., spreadsheets)  
  * The data process: wrangling, cleaning, analysis, and visualization  
  * Pandas basics  
* Curriculum for this session:  
  * Rebecca Krisel's [Intro to Pandas](https://github.com/rskrisel/pandas/blob/main/pandas_workshop_2024.ipynb)  
  * Rebecca Krisel Intro to Plotly (TBD)  
* Homework:  
  * Quiz due at 10am prior to class (See Assignment section in Courseworks) 
* Additional readings/resources (not required, but useful\!):  
  * Explainers:  
    * Harvard Business School: [Data Wrangling: What It Is & Why It's Important](https://online.hbs.edu/blog/post/data-wrangling)  
    * Stack Abuse: [Guide to Data Visualization in Python with Pandas](https://stackabuse.com/introduction-to-data-visualization-in-python-with-pandas/)  
    * Tableau: [Guide To Data Cleaning: Definition, Benefits, Components, And How To Clean Your Data](https://www.tableau.com/learn/articles/what-is-data-cleaning)  
    * Towards Data Science: [4 Reasons Why Plotly Is The Best Visualization Library](https://towardsdatascience.com/4-reasons-why-plotly-is-the-best-visualization-library-18c27de05b95#:~:text=Compared%20to%20traditional%20visualization%20tools,your%20data%20before%20plotting%20it.)

**Session 3: Text Analysis with NLTK (10/04/25)**

Principles of text analysis: Cleaning and processing text for analysis with the NLTK library  
This week, we will work with the Natural Language Toolkit (NLTK), a suite of Python libraries for processing and manipulating text-data. We will also review the necessary steps for cleaning and processing our text before we can analyze it by essentially converting each word in a text into an individual data point.

* Topics covered:  
  * Working with text-as-data  
  * Cleaning and standardizing text data  
  * Preparing texts for computational analysis  
  * Basic text analysis tools  
* Curriculum for this session:  
  * Rebecca Krisel's [Introduction to NLTK](https://github.com/rskrisel/intro_to_nltk/blob/main/Intro_NLTK_workshop.ipynb)  
* Homework:  
  * Assignment due at 10am prior to class  
* Additional readings/resources (not required, but useful\!):  
  * Tutorials:  
    * Geeks for Geeks: [Generating Word Cloud in Python](https://www.geeksforgeeks.org/generating-word-cloud-python/#:~:text=For%20generating%20word%20cloud%20in,from%20UCI%20Machine%20Learning%20Repository)  
  * Explainer:  
    * Scribbr: [Textual Analysis | Guide, 3 Approaches & Examples](https://www.scribbr.com/methodology/textual-analysis/)  
  * Projects:  
    * Digital Humanities at Yale University Library: [Robots Reading Vogue](http://dh.library.yale.edu/projects/vogue/)  
    * Boston College Library: [Text and Data Mining Projects](https://libguides.bc.edu/textdatamining/projects)

**Session 4: LLMs, Game Building & App Prototyping**

This week, we’ll explore how to use large language models (LLMs) like ChatGPT to support and accelerate your Python learning. We’ll begin by experimenting with prompt engineering to generate, debug, and explain Python code. Then, we’ll introduce simple game logic and app-building concepts that allow you to create interactive tools—such as text-based simulations or policy explainers—using Python and Streamlit. This session is about experimentation, creativity, and building confidence in your ability to use AI as a coding collaborator.

* **Topics covered:**  
  * Prompting ChatGPT to debug and scaffold Python code  
  * Building text-based games with conditionals and logic  
  * Creating interactive apps using Streamlit  
  * Prototyping policy tools or explainers with LLM support  
* Curriculum for this session:  
  * Martin Breuss, [ChatGPT: Your Personal Python Coding Mentor](https://realpython.com/chatgpt-coding-mentor-python/)  
  * TBD  
* Homework:  
  * Assignment due at 10am prior to class  
* Additional readings/resources (not required, but useful\!):  
  * TBD




**SIPA Academic Integrity Statement:**   
*The School of International & Public Affairs does not tolerate cheating or plagiarism in any form. Students who violate the Code of Academic & Professional Conduct will be subject to the Dean’s Disciplinary Procedures.* 

*Please familiarize yourself with the proper methods of citation and attribution. The School provides some valuable resources online; we strongly encourage you to familiarize yourself with these various styles before conducting research. Cut and paste the following link into your browser to view the Code of Academic & Professional Conduct and to access useful resources on citation and attribution: [http://bulletin.columbia.edu/sipa/academic-policies/](http://bulletin.columbia.edu/sipa/academic-policies/)*

*Violations of the Code of Academic & Professional Conduct should be reported to the Associate Dean for Student Affairs.*

**SIPA Disability Statement:**   
*SIPA is committed to ensuring that students registered with [Columbia University’s Disability Services](https://health.columbia.edu/content/disability-services) (DS) receive the reasonable accommodations necessary to participate fully in their academic programs. If you are a student with a disability and have a DS-certified accommodation letter, you may wish to make an appointment with your course instructor to discuss your accommodations. Faculty provide disability accommodations to students with DS-certified accommodation letters, and they provide the accommodations specified in such letters.  If you have any additional questions, please contact SIPA’s DS liaison at disability@sipa.columbia.edu or 212-854-8690.*

